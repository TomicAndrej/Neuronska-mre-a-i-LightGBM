{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalne metode u softverskom inženjerstvu\n",
    "## ```Projektni zadatak broj 2 - Andrej Tomić 1106/22```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuronska mreža"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Precision: 0.7978, Recall: 0.4734\n",
      "Epoch 2/10, Precision: 0.8640, Recall: 0.5754\n",
      "Epoch 3/10, Precision: 0.8262, Recall: 0.6412\n",
      "Epoch 4/10, Precision: 0.8340, Recall: 0.6544\n",
      "Epoch 5/10, Precision: 0.8354, Recall: 0.6553\n",
      "Epoch 6/10, Precision: 0.8307, Recall: 0.6597\n",
      "Epoch 7/10, Precision: 0.8313, Recall: 0.6616\n",
      "Epoch 8/10, Precision: 0.8462, Recall: 0.6250\n",
      "Epoch 9/10, Precision: 0.8344, Recall: 0.6547\n",
      "Epoch 10/10, Precision: 0.8288, Recall: 0.6553\n",
      "\n",
      "\n",
      "Najbolja preciznost: 0.8640\n",
      "Najbolji odziv: 0.5754\n",
      "Trening neuronske mreže završen.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Učitavanje RCV1 skupa podataka\n",
    "rcv1 = fetch_rcv1()\n",
    "\n",
    "# Ekstrahovanje podataka i ciljeva (koristimo 10000 uzoraka za manju memorijsku potrošnju)                                                                    \n",
    "X = rcv1.data[20000:30000].toarray()\n",
    "y = rcv1.target[20000:30000].toarray()\n",
    "\n",
    "# Standardizacija podataka\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Konverzija u Tensor format\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Kreiranje TensorDataset-a\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Podela na trening i test skup (50% za trening, 50% za test)\n",
    "train_size = len(dataset) // 2\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Kreiranje DataLoader-a\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Inicijalizacija mreže\n",
    "input_size = X_tensor.shape[1]\n",
    "output_size = y_tensor.shape[1]\n",
    "model = SimpleNN(input_size, output_size)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binarna klasifikacija\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "best_recall = 0.0\n",
    "best_precision = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluacija na testnom skupu\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    precision = precision_score(all_labels.cpu(), all_preds.cpu(), average='micro')\n",
    "    recall = recall_score(all_labels.cpu(), all_preds.cpu(), average='micro')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "    \n",
    "    # Sačuvaj model ako ima bolje performanse\n",
    "    if precision > best_precision:\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "\n",
    "print(f\"\\n\\nNajbolja preciznost: {best_precision:.4f}\")\n",
    "print(f\"Najbolji odziv: {best_recall:.4f}\")\n",
    "print('Trening neuronske mreže završen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 09:46:22,178] A new study created in memory with name: no-name-0526f2c5-3d61-41cd-8727-0f86af8855af\n",
      "[I 2024-06-26 09:47:01,008] Trial 0 finished with value: 0.7744 and parameters: {'lambda_l1': 0.564830610876858, 'lambda_l2': 0.014845666863006183, 'num_leaves': 202, 'feature_fraction': 0.8969880195218041, 'bagging_fraction': 0.4123559945662514, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 0 with value: 0.7744.\n",
      "[I 2024-06-26 09:47:45,757] Trial 1 finished with value: 0.7728 and parameters: {'lambda_l1': 3.3423090833078304e-05, 'lambda_l2': 1.4343593766578642e-07, 'num_leaves': 207, 'feature_fraction': 0.7449490654863375, 'bagging_fraction': 0.9826465352862168, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 1 with value: 0.7728.\n",
      "[I 2024-06-26 09:48:32,430] Trial 2 finished with value: 0.773 and parameters: {'lambda_l1': 3.424988314899009e-05, 'lambda_l2': 5.570278067137863e-07, 'num_leaves': 202, 'feature_fraction': 0.5780809759832684, 'bagging_fraction': 0.603297400220742, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 1 with value: 0.7728.\n",
      "[I 2024-06-26 09:48:59,032] Trial 3 finished with value: 0.7734 and parameters: {'lambda_l1': 2.5869676821871286, 'lambda_l2': 0.019474238923736314, 'num_leaves': 59, 'feature_fraction': 0.6347271935811625, 'bagging_fraction': 0.7830512097882485, 'bagging_freq': 6, 'min_child_samples': 86}. Best is trial 1 with value: 0.7728.\n",
      "[I 2024-06-26 09:49:42,060] Trial 4 finished with value: 0.7748 and parameters: {'lambda_l1': 1.6130613995836022e-06, 'lambda_l2': 1.0654546890043311e-08, 'num_leaves': 48, 'feature_fraction': 0.5689297406193458, 'bagging_fraction': 0.7693116355922087, 'bagging_freq': 3, 'min_child_samples': 90}. Best is trial 1 with value: 0.7728.\n",
      "[I 2024-06-26 09:49:58,734] Trial 5 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-26 09:50:17,831] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-26 09:50:33,563] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-26 09:50:50,619] Trial 8 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-26 09:51:09,392] Trial 9 pruned. Trial was pruned at iteration 4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 10\n",
      "Best trial:\n",
      "  Value: 0.7728\n",
      "  Params: \n",
      "    lambda_l1: 3.3423090833078304e-05\n",
      "    lambda_l2: 1.4343593766578642e-07\n",
      "    num_leaves: 207\n",
      "    feature_fraction: 0.7449490654863375\n",
      "    bagging_fraction: 0.9826465352862168\n",
      "    bagging_freq: 4\n",
      "    min_child_samples: 70\n",
      "\n",
      "\n",
      "Preciznost na test skupu: 0.7271395787113216\n",
      "Odziv na test skupu: 0.7398\n",
      "Trening LightGBM modela završen.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "y_train_np = np.asarray(y[:train_size].argmax(axis=1)).ravel()\n",
    "y_test_np = np.asarray(y[train_size:].argmax(axis=1)).ravel()\n",
    "\n",
    "X_train_search, X_valid_search, y_train_search, y_valid_search = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Konvertovanje oznaka u 1-D numpy niz\n",
    "y_train_search = np.argmax(y_train_search, axis=1)\n",
    "y_valid_search = np.argmax(y_valid_search, axis=1)\n",
    "\n",
    "# Definicija objective funkcije za Optuna\n",
    "def objective(trial):\n",
    "    # Definicija prostora pretrage hiperparametara\n",
    "    param = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_class\": y.shape[1],\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"verbose\": -1  # Uključi verbose opciju ovde\n",
    "    }\n",
    "\n",
    "    # Kreiraj LightGBM dataset\n",
    "    dtrain = lgb.Dataset(X_train_search, label=y_train_search)\n",
    "    dvalid = lgb.Dataset(X_valid_search, label=y_valid_search)\n",
    "\n",
    "    # Kreiraj Optuna pruning callback\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"multi_logloss\", valid_name=\"valid_0\")\n",
    "\n",
    "    # Treniraj model\n",
    "    model = lgb.train(param, dtrain, valid_sets=[dvalid], callbacks=[pruning_callback])\n",
    "\n",
    "    # Evaluiraj model na validacionom skupu\n",
    "    y_pred = model.predict(X_valid_search)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(y_valid_search, y_pred_labels)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Kreiraj Optuna studiju i optimizuj\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "# Definiši najbolje pronađene parametre od strane Optuna\n",
    "best_params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_class\": output_size,\n",
    "    \"lambda_l1\": study.best_params[\"lambda_l1\"], \n",
    "    \"lambda_l2\": study.best_params[\"lambda_l2\"],\n",
    "    \"num_leaves\": study.best_params[\"num_leaves\"],\n",
    "    \"feature_fraction\": study.best_params[\"feature_fraction\"],\n",
    "    \"bagging_fraction\": study.best_params[\"bagging_fraction\"],\n",
    "    \"bagging_freq\": study.best_params[\"bagging_freq\"],\n",
    "    \"min_child_samples\": study.best_params[\"min_child_samples\"],\n",
    "}\n",
    "\n",
    "# Train LightGBM model with the best parameters on the full training set\n",
    "dtrain_full = lgb.Dataset(X[:train_size], label=y_train_np)\n",
    "best_model = lgb.train(best_params, dtrain_full)\n",
    "\n",
    "# Računanje preciznosti i odziva na test skupu\n",
    "y_pred = best_model.predict(X[train_size:], num_iteration=best_model.best_iteration)\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "precision_lgbm = precision_score(y_test_np, y_pred_binary, average='weighted', zero_division=0)\n",
    "recall_lgbm = recall_score(y_test_np, y_pred_binary, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\n\\nPreciznost na test skupu: {precision_lgbm}\")\n",
    "print(f\"Odziv na test skupu: {recall_lgbm}\")\n",
    "print('Trening LightGBM modela završen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poređenje - Neuronska mreža vs LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronska mreža je postigla veću preciznost na testnom skupu.\n"
     ]
    }
   ],
   "source": [
    "if best_precision > precision_lgbm:\n",
    "    print(\"Neuronska mreža je postigla veću preciznost na testnom skupu.\")\n",
    "elif best_precision < precision_lgbm:\n",
    "    print(\"LightGBM je postigao veću preciznost na testnom skupu.\")\n",
    "else:\n",
    "    print(\"Oba modela su postigla istu preciznost na testnom skupu.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
